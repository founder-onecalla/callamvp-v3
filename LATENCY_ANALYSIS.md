# OneCalla Latency Analysis

## Executive Summary

The most critical latency path is **Voice Agent Response** (person speaks â†’ AI responds), which currently has **6 sequential operations** totaling an estimated **3-6 seconds**. This is too slow for natural conversation.

---

## 1. Voice Agent Response Latency (CRITICAL)

**Path:** Person speaks â†’ AI responds audibly

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CURRENT FLOW (Sequential - ~3-6 seconds)                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  Person speaks                                                              â”‚
â”‚       â†“                                                                     â”‚
â”‚  [~500-1000ms] Telnyx transcription processing                              â”‚
â”‚       â†“                                                                     â”‚
â”‚  [~100ms] Webhook receives transcription                                    â”‚
â”‚       â†“                                                                     â”‚
â”‚  [~50ms] Insert transcription to DB                                         â”‚
â”‚       â†“                                                                     â”‚
â”‚  [~100ms] HTTP call to voice-agent function                                 â”‚
â”‚       â†“                                                                     â”‚
â”‚  [~200ms] Edge function cold start (if cold)                                â”‚
â”‚       â†“                                                                     â”‚
â”‚  [~100ms] 4 sequential DB queries (call, context, transcriptions, events)   â”‚
â”‚       â†“                                                                     â”‚
â”‚  [~1000-2000ms] GPT-4 API call                                              â”‚
â”‚       â†“                                                                     â”‚
â”‚  [~500-1000ms] ElevenLabs TTS (UNUSED - we use Telnyx speak)                â”‚
â”‚       â†“                                                                     â”‚
â”‚  [~200ms] Telnyx speak API call                                             â”‚
â”‚       â†“                                                                     â”‚
â”‚  [~50ms] Insert agent_speech event to DB                                    â”‚
â”‚       â†“                                                                     â”‚
â”‚  [~300-500ms] Telnyx TTS rendering + playback start                         â”‚
â”‚       â†“                                                                     â”‚
â”‚  Person hears AI response                                                   â”‚
â”‚                                                                             â”‚
â”‚  TOTAL: ~3000-6000ms (unacceptable for conversation)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Issues Identified:

| Issue | Location | Impact | Fix |
|-------|----------|--------|-----|
| 4 sequential DB queries | voice-agent:176-210 | +400ms | Parallelize with Promise.all() |
| ElevenLabs called but unused | voice-agent:268 | +500-1000ms | Remove (using Telnyx speak) |
| GPT-4-turbo is slow | voice-agent:97 | +1000-2000ms | Use GPT-4o or GPT-3.5-turbo |
| Cold start penalty | Edge function | +200ms | Keep warm or use streaming |
| No streaming response | voice-agent | +latency | Stream GPT â†’ Telnyx |

### Recommended Optimizations:

```typescript
// BEFORE: Sequential queries (~400ms)
const { data: call } = await serviceClient.from('calls')...
const { data: context } = await serviceClient.from('call_contexts')...
const { data: transcriptions } = await serviceClient.from('transcriptions')...
const { data: agentEvents } = await serviceClient.from('call_events')...

// AFTER: Parallel queries (~100ms)
const [callResult, contextResult, transcriptionsResult, eventsResult] = await Promise.all([
  serviceClient.from('calls').select('*').eq('id', call_id).single(),
  serviceClient.from('call_contexts').select('*').eq('call_id', call_id).maybeSingle(),
  serviceClient.from('transcriptions').select('*').eq('call_id', call_id).order('created_at'),
  serviceClient.from('call_events').select('*').eq('call_id', call_id).eq('event_type', 'agent_speech').order('created_at')
])
```

```typescript
// BEFORE: GPT-4-turbo (~1500ms average)
model: 'gpt-4-turbo-preview'

// AFTER: GPT-4o (~500ms average) or GPT-3.5-turbo (~300ms)
model: 'gpt-4o'  // Faster, same quality for short responses
```

```typescript
// REMOVE: ElevenLabs TTS is generated but never used
const audioBuffer = await textToSpeech(elevenLabsKey, responseText)  // DELETE THIS LINE
```

---

## 2. Chat Response Latency

**Path:** User types message â†’ AI response appears

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CURRENT FLOW (~1.5-3 seconds)                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  User sends message                                                         â”‚
â”‚       â†“                                                                     â”‚
â”‚  [~100ms] Supabase function invoke                                          â”‚
â”‚       â†“                                                                     â”‚
â”‚  [~200ms] Edge function cold start (if cold)                                â”‚
â”‚       â†“                                                                     â”‚
â”‚  [~50ms] Auth validation                                                    â”‚
â”‚       â†“                                                                     â”‚
â”‚  [~100ms] 3 sequential DB queries (memories, contacts, IVR paths)           â”‚
â”‚       â†“                                                                     â”‚
â”‚  [~1000-2000ms] GPT-4 API call                                              â”‚
â”‚       â†“                                                                     â”‚
â”‚  [~50ms] Execute any function calls (save_memory, etc.)                     â”‚
â”‚       â†“                                                                     â”‚
â”‚  [~50ms] Store messages in DB                                               â”‚
â”‚       â†“                                                                     â”‚
â”‚  Response displayed                                                         â”‚
â”‚                                                                             â”‚
â”‚  TOTAL: ~1500-3000ms (acceptable but could improve)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Optimizations:

| Issue | Fix | Savings |
|-------|-----|---------|
| Sequential DB queries | Parallelize getUserContext() | ~100ms |
| GPT-4-turbo | Use GPT-4o | ~500ms |
| No streaming | Implement SSE streaming | Perceived -1000ms |

---

## 3. Call Initiation Latency

**Path:** User confirms â†’ Phone rings

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CURRENT FLOW (~1-2 seconds)                                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  User says "yes"                                                            â”‚
â”‚       â†“                                                                     â”‚
â”‚  [~1500ms] Chat function processes, returns place_call                      â”‚
â”‚       â†“                                                                     â”‚
â”‚  [~100ms] Frontend calls call-start function                                â”‚
â”‚       â†“                                                                     â”‚
â”‚  [~50ms] Auth + create call record                                          â”‚
â”‚       â†“                                                                     â”‚
â”‚  [~200ms] Telnyx API initiates call                                         â”‚
â”‚       â†“                                                                     â”‚
â”‚  [~50ms] Update call with telnyx_call_id                                    â”‚
â”‚       â†“                                                                     â”‚
â”‚  Phone starts ringing                                                       â”‚
â”‚                                                                             â”‚
â”‚  TOTAL: ~1900ms (acceptable)                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 4. Transcription Display Latency

**Path:** Person speaks â†’ Text appears in UI

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CURRENT FLOW (~1-2 seconds)                                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  Person speaks                                                              â”‚
â”‚       â†“                                                                     â”‚
â”‚  [~500-1000ms] Telnyx STT processing                                        â”‚
â”‚       â†“                                                                     â”‚
â”‚  [~100ms] Webhook receives event                                            â”‚
â”‚       â†“                                                                     â”‚
â”‚  [~50ms] Insert to transcriptions table                                     â”‚
â”‚       â†“                                                                     â”‚
â”‚  [~100-200ms] Supabase Realtime propagation                                 â”‚
â”‚       â†“                                                                     â”‚
â”‚  [~50ms] React state update + render                                        â”‚
â”‚       â†“                                                                     â”‚
â”‚  Text appears in UI                                                         â”‚
â”‚                                                                             â”‚
â”‚  TOTAL: ~800-1500ms (acceptable for display)                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 5. Post-Call Summary Latency

**Path:** Call ends â†’ Summary displayed

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CURRENT FLOW (~2-4 seconds)                                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  Call ends (hangup event)                                                   â”‚
â”‚       â†“                                                                     â”‚
â”‚  [~100ms] Webhook updates call status                                       â”‚
â”‚       â†“                                                                     â”‚
â”‚  [~100ms] Realtime notifies frontend                                        â”‚
â”‚       â†“                                                                     â”‚
â”‚  [~100ms] Frontend calls call-summary function                              â”‚
â”‚       â†“                                                                     â”‚
â”‚  [~200ms] 4 sequential DB queries                                           â”‚
â”‚       â†“                                                                     â”‚
â”‚  [~1500-2500ms] GPT-4 generates summary                                     â”‚
â”‚       â†“                                                                     â”‚
â”‚  [~50ms] Store summary message                                              â”‚
â”‚       â†“                                                                     â”‚
â”‚  Summary displayed                                                          â”‚
â”‚                                                                             â”‚
â”‚  TOTAL: ~2000-4000ms (acceptable, not time-critical)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Optimizations:

| Issue | Fix | Savings |
|-------|-----|---------|
| Sequential DB queries | Parallelize | ~150ms |
| GPT-4-turbo | Use GPT-4o or GPT-3.5-turbo | ~500-1000ms |

---

## 6. Call History Load Latency

**Path:** Opens history â†’ Data appears

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CURRENT FLOW (~200-500ms)                                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  User expands call history                                                  â”‚
â”‚       â†“                                                                     â”‚
â”‚  [~100-300ms] Supabase query with JOIN                                      â”‚
â”‚       â†“                                                                     â”‚
â”‚  [~50ms] React state update                                                 â”‚
â”‚       â†“                                                                     â”‚
â”‚  [~50ms] Render cards                                                       â”‚
â”‚       â†“                                                                     â”‚
â”‚  History displayed                                                          â”‚
â”‚                                                                             â”‚
â”‚  TOTAL: ~200-500ms (good)                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Priority Fixes

### ğŸ”´ Critical (Voice Agent - affects conversation quality)

1. **Remove unused ElevenLabs call** - Saves 500-1000ms
2. **Parallelize DB queries** - Saves ~300ms
3. **Switch to GPT-4o** - Saves ~500-1000ms
4. **Total potential savings: 1.3-2.3 seconds**

### ğŸŸ¡ Important (Chat - affects UX)

1. **Parallelize getUserContext()** - Saves ~100ms
2. **Switch to GPT-4o** - Saves ~500ms
3. **Consider streaming responses** - Perceived improvement

### ğŸŸ¢ Nice to Have

1. **Edge function warm-up** - Saves cold start penalty
2. **Response caching** - For repeated queries
3. **Optimistic UI updates** - Perceived improvement

---

## Benchmark Targets

| Operation | Current | Target | Status |
|-----------|---------|--------|--------|
| Voice Agent Response | 3-6s | <1.5s | ğŸ”´ Critical |
| Chat Response | 1.5-3s | <1s | ğŸŸ¡ Needs work |
| Call Initiation | ~2s | <2s | ğŸŸ¢ OK |
| Transcription Display | 1-1.5s | <1s | ğŸŸ¢ OK |
| Post-Call Summary | 2-4s | <2s | ğŸŸ¡ Nice to have |
| Call History Load | 0.2-0.5s | <0.5s | ğŸŸ¢ OK |

---

## Implementation Priority

1. **voice-agent optimization** (HIGHEST IMPACT)
   - Remove ElevenLabs call
   - Parallelize queries
   - Switch model

2. **chat optimization**
   - Parallelize queries
   - Switch model

3. **call-summary optimization**
   - Parallelize queries
   - Consider GPT-3.5-turbo (simpler task)
